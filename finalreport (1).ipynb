{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06310556-db38-4b28-876b-ee8ea7b333df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.98       359\n",
      "           1       0.93      0.98      0.96       188\n",
      "\n",
      "    accuracy                           0.97       547\n",
      "   macro avg       0.96      0.97      0.97       547\n",
      "weighted avg       0.97      0.97      0.97       547\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       359\n",
      "           1       0.95      0.97      0.96       188\n",
      "\n",
      "    accuracy                           0.97       547\n",
      "   macro avg       0.97      0.97      0.97       547\n",
      "weighted avg       0.97      0.97      0.97       547\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.289088\n",
      "2  cell_shape_uniformity    0.265420\n",
      "4   epithelial_cell_size    0.118238\n",
      "5            bare_nuclei    0.117994\n",
      "3      marginal_adhesion    0.082844\n",
      "6        bland_chromatin    0.066453\n",
      "0        clump_thickness    0.040691\n",
      "7        normal_nucleoli    0.013677\n",
      "8                mitoses    0.005597\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       359\n",
      "           1       0.96      0.97      0.97       188\n",
      "\n",
      "    accuracy                           0.98       547\n",
      "   macro avg       0.97      0.97      0.97       547\n",
      "weighted avg       0.98      0.98      0.98       547\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.96      0.97       357\n",
      "           1       0.93      0.97      0.95       190\n",
      "\n",
      "    accuracy                           0.96       547\n",
      "   macro avg       0.96      0.97      0.96       547\n",
      "weighted avg       0.96      0.96      0.96       547\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       357\n",
      "           1       0.93      0.93      0.93       190\n",
      "\n",
      "    accuracy                           0.95       547\n",
      "   macro avg       0.94      0.94      0.94       547\n",
      "weighted avg       0.95      0.95      0.95       547\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "2  cell_shape_uniformity    0.354720\n",
      "1   cell_size_uniformity    0.344632\n",
      "5            bare_nuclei    0.111725\n",
      "3      marginal_adhesion    0.053455\n",
      "7        normal_nucleoli    0.040656\n",
      "4   epithelial_cell_size    0.036275\n",
      "6        bland_chromatin    0.029723\n",
      "0        clump_thickness    0.026904\n",
      "8                mitoses    0.001911\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97       357\n",
      "           1       0.94      0.94      0.94       190\n",
      "\n",
      "    accuracy                           0.96       547\n",
      "   macro avg       0.95      0.95      0.95       547\n",
      "weighted avg       0.96      0.96      0.96       547\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       355\n",
      "           1       0.94      0.97      0.96       192\n",
      "\n",
      "    accuracy                           0.97       547\n",
      "   macro avg       0.96      0.97      0.97       547\n",
      "weighted avg       0.97      0.97      0.97       547\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       355\n",
      "           1       0.96      0.96      0.96       192\n",
      "\n",
      "    accuracy                           0.97       547\n",
      "   macro avg       0.97      0.97      0.97       547\n",
      "weighted avg       0.97      0.97      0.97       547\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "5            bare_nuclei    0.206029\n",
      "1   cell_size_uniformity    0.202812\n",
      "2  cell_shape_uniformity    0.191544\n",
      "6        bland_chromatin    0.136357\n",
      "4   epithelial_cell_size    0.095789\n",
      "0        clump_thickness    0.085897\n",
      "7        normal_nucleoli    0.042547\n",
      "3      marginal_adhesion    0.036328\n",
      "8                mitoses    0.002698\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       355\n",
      "           1       0.96      0.94      0.95       192\n",
      "\n",
      "    accuracy                           0.97       547\n",
      "   macro avg       0.96      0.96      0.96       547\n",
      "weighted avg       0.97      0.97      0.97       547\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       218\n",
      "           1       0.97      0.93      0.95       124\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.96      0.95      0.96       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97       218\n",
      "           1       0.97      0.92      0.95       124\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.96      0.95      0.96       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.312440\n",
      "2  cell_shape_uniformity    0.234759\n",
      "5            bare_nuclei    0.179926\n",
      "6        bland_chromatin    0.097188\n",
      "7        normal_nucleoli    0.048359\n",
      "4   epithelial_cell_size    0.047396\n",
      "0        clump_thickness    0.040246\n",
      "3      marginal_adhesion    0.027987\n",
      "8                mitoses    0.011699\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97       218\n",
      "           1       0.98      0.90      0.94       124\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.96      0.94      0.95       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97       228\n",
      "           1       0.90      0.97      0.94       114\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.94      0.96      0.95       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       228\n",
      "           1       0.92      0.96      0.94       114\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.95      0.96      0.96       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.339023\n",
      "2  cell_shape_uniformity    0.233634\n",
      "5            bare_nuclei    0.142194\n",
      "4   epithelial_cell_size    0.100056\n",
      "6        bland_chromatin    0.068891\n",
      "3      marginal_adhesion    0.050495\n",
      "0        clump_thickness    0.036640\n",
      "7        normal_nucleoli    0.028136\n",
      "8                mitoses    0.000928\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       228\n",
      "           1       0.92      0.96      0.94       114\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.95      0.96      0.95       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       225\n",
      "           1       0.96      0.95      0.95       117\n",
      "\n",
      "    accuracy                           0.97       342\n",
      "   macro avg       0.97      0.96      0.96       342\n",
      "weighted avg       0.97      0.97      0.97       342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       225\n",
      "           1       0.96      0.97      0.96       117\n",
      "\n",
      "    accuracy                           0.97       342\n",
      "   macro avg       0.97      0.97      0.97       342\n",
      "weighted avg       0.97      0.97      0.97       342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.262924\n",
      "2  cell_shape_uniformity    0.222069\n",
      "5            bare_nuclei    0.187059\n",
      "6        bland_chromatin    0.096779\n",
      "0        clump_thickness    0.073617\n",
      "4   epithelial_cell_size    0.070296\n",
      "7        normal_nucleoli    0.057055\n",
      "3      marginal_adhesion    0.027018\n",
      "8                mitoses    0.003183\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       225\n",
      "           1       0.96      0.93      0.95       117\n",
      "\n",
      "    accuracy                           0.96       342\n",
      "   macro avg       0.96      0.96      0.96       342\n",
      "weighted avg       0.96      0.96      0.96       342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97        79\n",
      "           1       0.96      0.95      0.96        58\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        79\n",
      "           1       0.98      0.90      0.94        58\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.95       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.355546\n",
      "2  cell_shape_uniformity    0.223125\n",
      "5            bare_nuclei    0.124688\n",
      "6        bland_chromatin    0.100173\n",
      "7        normal_nucleoli    0.089470\n",
      "0        clump_thickness    0.037789\n",
      "4   epithelial_cell_size    0.036581\n",
      "3      marginal_adhesion    0.023301\n",
      "8                mitoses    0.009328\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        79\n",
      "           1       0.98      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96        88\n",
      "           1       0.92      0.94      0.93        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.95      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96        88\n",
      "           1       0.96      0.90      0.93        49\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.95      0.94      0.94       137\n",
      "weighted avg       0.95      0.95      0.95       137\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.312849\n",
      "2  cell_shape_uniformity    0.241495\n",
      "5            bare_nuclei    0.130490\n",
      "6        bland_chromatin    0.090141\n",
      "4   epithelial_cell_size    0.080198\n",
      "7        normal_nucleoli    0.060197\n",
      "0        clump_thickness    0.053821\n",
      "3      marginal_adhesion    0.024529\n",
      "8                mitoses    0.006280\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95        88\n",
      "           1       0.95      0.86      0.90        49\n",
      "\n",
      "    accuracy                           0.93       137\n",
      "   macro avg       0.94      0.92      0.93       137\n",
      "weighted avg       0.94      0.93      0.93       137\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        86\n",
      "           1       0.92      0.96      0.94        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97        86\n",
      "           1       0.94      0.96      0.95        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.96      0.96      0.96       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                 Feature  Importance\n",
      "1   cell_size_uniformity    0.297701\n",
      "2  cell_shape_uniformity    0.238522\n",
      "5            bare_nuclei    0.134010\n",
      "6        bland_chromatin    0.105564\n",
      "4   epithelial_cell_size    0.073885\n",
      "7        normal_nucleoli    0.051158\n",
      "0        clump_thickness    0.048248\n",
      "3      marginal_adhesion    0.043231\n",
      "8                mitoses    0.007681\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        86\n",
      "           1       0.92      0.96      0.94        51\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n",
      "\n",
      "Average Results:\n",
      "                           Train Score  Test Score  CV Score\n",
      "Model         Train Ratio                                   \n",
      "KNN           0.2             0.973039    0.966484  0.970635\n",
      "              0.5             0.979472    0.959064  0.970645\n",
      "              0.8             0.977411    0.948905  0.968268\n",
      "Random Forest 0.2             1.000000    0.964046  0.968254\n",
      "              0.5             1.000000    0.965887  0.968670\n",
      "              0.8             1.000000    0.953771  0.971927\n",
      "SVM           0.2             0.977941    0.967093  0.963492\n",
      "              0.5             0.979472    0.961988  0.971640\n",
      "              0.8             0.979243    0.956204  0.967640\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class BreastCancerAnalysis:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def load_data(self, filepath):\n",
    "        # Define column names\n",
    "        columns = ['id', 'clump_thickness', 'cell_size_uniformity', \n",
    "                  'cell_shape_uniformity', 'marginal_adhesion', \n",
    "                  'epithelial_cell_size', 'bare_nuclei', 'bland_chromatin',\n",
    "                  'normal_nucleoli', 'mitoses', 'class']\n",
    "        \n",
    "        # Read the data\n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        \n",
    "        # Handle missing values\n",
    "        df = df.replace('?', np.nan)\n",
    "        df = df.dropna()\n",
    "        \n",
    "        # Convert to numeric\n",
    "        for col in df.columns:\n",
    "            if col != 'id':\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "        \n",
    "        # Convert class to binary (2: benign -> 0, 4: malignant -> 1)\n",
    "        df['class'] = (df['class'] == 4).astype(int)\n",
    "        \n",
    "        # Separate features and target\n",
    "        X = df.drop(['id', 'class'], axis=1)\n",
    "        y = df['class']\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "        \n",
    "        return X_scaled, y\n",
    "    \n",
    "    def train_and_evaluate(self, X, y, train_ratio, trial):\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=(1-train_ratio), random_state=self.random_state+trial\n",
    "        )\n",
    "        \n",
    "        models = {\n",
    "            'SVM': SVC(random_state=self.random_state),\n",
    "            'Random Forest': RandomForestClassifier(random_state=self.random_state),\n",
    "            'KNN': KNeighborsClassifier()\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        for name, model in models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Calculate scores\n",
    "            train_score = model.score(X_train, y_train)\n",
    "            test_score = model.score(X_test, y_test)\n",
    "            cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Train Ratio': train_ratio,\n",
    "                'Train Score': train_score,\n",
    "                'Test Score': test_score,\n",
    "                'CV Score': cv_score,\n",
    "                'Trial': trial\n",
    "            })\n",
    "            \n",
    "            # Print detailed results for this model\n",
    "            print(f\"\\nResults for {name} (Trial {trial}, Train Ratio {train_ratio}):\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Print feature importance for Random Forest\n",
    "            if name == 'Random Forest':\n",
    "                importance = pd.DataFrame({\n",
    "                    'Feature': X.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                print(\"\\nFeature Importance:\")\n",
    "                print(importance)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    # Initialize analysis\n",
    "    analysis = BreastCancerAnalysis()\n",
    "    \n",
    "    # Load data\n",
    "    X, y = analysis.load_data('breast-cancer-wisconsin.data')\n",
    "    \n",
    "    # Test different train/test ratios\n",
    "    train_ratios = [0.2, 0.5, 0.8]\n",
    "    all_results = []\n",
    "    \n",
    "    for train_ratio in train_ratios:\n",
    "        for trial in range(3):\n",
    "            results = analysis.train_and_evaluate(X, y, train_ratio, trial)\n",
    "            all_results.append(results)\n",
    "    \n",
    "    # Combine and display final results\n",
    "    final_results = pd.concat(all_results)\n",
    "    print(\"\\nAverage Results:\")\n",
    "    print(final_results.groupby(['Model', 'Train Ratio'])[['Train Score', 'Test Score', 'CV Score']].mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3db2c68-725e-40bd-a274-04062a4d2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.91      0.84      2182\n",
      "           1       0.75      0.49      0.59      1160\n",
      "\n",
      "    accuracy                           0.77      3342\n",
      "   macro avg       0.76      0.70      0.71      3342\n",
      "weighted avg       0.76      0.77      0.75      3342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.87      0.83      2182\n",
      "           1       0.70      0.58      0.63      1160\n",
      "\n",
      "    accuracy                           0.77      3342\n",
      "   macro avg       0.75      0.72      0.73      3342\n",
      "weighted avg       0.76      0.77      0.76      3342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.197486\n",
      "5  Shucked_weight    0.168504\n",
      "4    Whole_weight    0.138465\n",
      "3          Height    0.121815\n",
      "2        Diameter    0.117302\n",
      "6  Viscera_weight    0.115785\n",
      "1          Length    0.105975\n",
      "0             Sex    0.034669\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.87      0.82      2182\n",
      "           1       0.68      0.52      0.59      1160\n",
      "\n",
      "    accuracy                           0.75      3342\n",
      "   macro avg       0.73      0.70      0.70      3342\n",
      "weighted avg       0.74      0.75      0.74      3342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      2210\n",
      "           1       0.70      0.64      0.67      1132\n",
      "\n",
      "    accuracy                           0.79      3342\n",
      "   macro avg       0.76      0.75      0.75      3342\n",
      "weighted avg       0.78      0.79      0.78      3342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.82      2210\n",
      "           1       0.66      0.65      0.65      1132\n",
      "\n",
      "    accuracy                           0.77      3342\n",
      "   macro avg       0.74      0.74      0.74      3342\n",
      "weighted avg       0.77      0.77      0.77      3342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.191149\n",
      "5  Shucked_weight    0.151161\n",
      "4    Whole_weight    0.142259\n",
      "3          Height    0.136526\n",
      "6  Viscera_weight    0.123250\n",
      "2        Diameter    0.120804\n",
      "1          Length    0.101712\n",
      "0             Sex    0.033139\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.81      0.80      2210\n",
      "           1       0.62      0.59      0.61      1132\n",
      "\n",
      "    accuracy                           0.74      3342\n",
      "   macro avg       0.71      0.70      0.70      3342\n",
      "weighted avg       0.74      0.74      0.74      3342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.83      2179\n",
      "           1       0.73      0.52      0.61      1163\n",
      "\n",
      "    accuracy                           0.77      3342\n",
      "   macro avg       0.76      0.71      0.72      3342\n",
      "weighted avg       0.76      0.77      0.76      3342\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.88      0.84      2179\n",
      "           1       0.72      0.58      0.64      1163\n",
      "\n",
      "    accuracy                           0.78      3342\n",
      "   macro avg       0.76      0.73      0.74      3342\n",
      "weighted avg       0.77      0.78      0.77      3342\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.212539\n",
      "4    Whole_weight    0.158675\n",
      "5  Shucked_weight    0.141550\n",
      "2        Diameter    0.126127\n",
      "6  Viscera_weight    0.122838\n",
      "3          Height    0.110265\n",
      "1          Length    0.099765\n",
      "0             Sex    0.028241\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82      2179\n",
      "           1       0.69      0.52      0.59      1163\n",
      "\n",
      "    accuracy                           0.75      3342\n",
      "   macro avg       0.73      0.70      0.71      3342\n",
      "weighted avg       0.74      0.75      0.74      3342\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85      1392\n",
      "           1       0.72      0.60      0.65       697\n",
      "\n",
      "    accuracy                           0.79      2089\n",
      "   macro avg       0.76      0.74      0.75      2089\n",
      "weighted avg       0.78      0.79      0.78      2089\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84      1392\n",
      "           1       0.69      0.62      0.65       697\n",
      "\n",
      "    accuracy                           0.78      2089\n",
      "   macro avg       0.75      0.74      0.75      2089\n",
      "weighted avg       0.77      0.78      0.78      2089\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.206749\n",
      "5  Shucked_weight    0.157653\n",
      "4    Whole_weight    0.145792\n",
      "3          Height    0.125426\n",
      "6  Viscera_weight    0.122318\n",
      "2        Diameter    0.115095\n",
      "1          Length    0.096011\n",
      "0             Sex    0.030956\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82      1392\n",
      "           1       0.65      0.57      0.61       697\n",
      "\n",
      "    accuracy                           0.75      2089\n",
      "   macro avg       0.72      0.71      0.71      2089\n",
      "weighted avg       0.75      0.75      0.75      2089\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      1370\n",
      "           1       0.72      0.60      0.65       719\n",
      "\n",
      "    accuracy                           0.78      2089\n",
      "   macro avg       0.76      0.74      0.75      2089\n",
      "weighted avg       0.77      0.78      0.77      2089\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84      1370\n",
      "           1       0.71      0.62      0.66       719\n",
      "\n",
      "    accuracy                           0.78      2089\n",
      "   macro avg       0.76      0.74      0.75      2089\n",
      "weighted avg       0.78      0.78      0.78      2089\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.201224\n",
      "5  Shucked_weight    0.152839\n",
      "4    Whole_weight    0.136504\n",
      "6  Viscera_weight    0.131642\n",
      "3          Height    0.127194\n",
      "2        Diameter    0.120342\n",
      "1          Length    0.098488\n",
      "0             Sex    0.031767\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82      1370\n",
      "           1       0.66      0.59      0.62       719\n",
      "\n",
      "    accuracy                           0.75      2089\n",
      "   macro avg       0.73      0.71      0.72      2089\n",
      "weighted avg       0.75      0.75      0.75      2089\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.84      1360\n",
      "           1       0.72      0.61      0.66       729\n",
      "\n",
      "    accuracy                           0.78      2089\n",
      "   macro avg       0.76      0.74      0.75      2089\n",
      "weighted avg       0.78      0.78      0.78      2089\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83      1360\n",
      "           1       0.70      0.63      0.66       729\n",
      "\n",
      "    accuracy                           0.78      2089\n",
      "   macro avg       0.75      0.74      0.75      2089\n",
      "weighted avg       0.77      0.78      0.77      2089\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.210678\n",
      "4    Whole_weight    0.152965\n",
      "5  Shucked_weight    0.147409\n",
      "6  Viscera_weight    0.122269\n",
      "3          Height    0.121803\n",
      "2        Diameter    0.120249\n",
      "1          Length    0.098103\n",
      "0             Sex    0.026524\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81      1360\n",
      "           1       0.67      0.56      0.61       729\n",
      "\n",
      "    accuracy                           0.75      2089\n",
      "   macro avg       0.72      0.70      0.71      2089\n",
      "weighted avg       0.74      0.75      0.74      2089\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.85       560\n",
      "           1       0.70      0.65      0.67       276\n",
      "\n",
      "    accuracy                           0.79       836\n",
      "   macro avg       0.76      0.75      0.76       836\n",
      "weighted avg       0.79      0.79      0.79       836\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       560\n",
      "           1       0.68      0.67      0.67       276\n",
      "\n",
      "    accuracy                           0.79       836\n",
      "   macro avg       0.76      0.76      0.76       836\n",
      "weighted avg       0.79      0.79      0.79       836\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.208299\n",
      "5  Shucked_weight    0.151887\n",
      "4    Whole_weight    0.144513\n",
      "6  Viscera_weight    0.128570\n",
      "3          Height    0.126537\n",
      "2        Diameter    0.112809\n",
      "1          Length    0.098479\n",
      "0             Sex    0.028906\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.82      0.82       560\n",
      "           1       0.64      0.64      0.64       276\n",
      "\n",
      "    accuracy                           0.76       836\n",
      "   macro avg       0.73      0.73      0.73       836\n",
      "weighted avg       0.76      0.76      0.76       836\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       555\n",
      "           1       0.72      0.63      0.67       281\n",
      "\n",
      "    accuracy                           0.79       836\n",
      "   macro avg       0.77      0.75      0.76       836\n",
      "weighted avg       0.79      0.79      0.79       836\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       555\n",
      "           1       0.70      0.59      0.64       281\n",
      "\n",
      "    accuracy                           0.78       836\n",
      "   macro avg       0.75      0.73      0.74       836\n",
      "weighted avg       0.77      0.78      0.77       836\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.201599\n",
      "5  Shucked_weight    0.155172\n",
      "4    Whole_weight    0.143100\n",
      "6  Viscera_weight    0.132572\n",
      "3          Height    0.121615\n",
      "2        Diameter    0.118310\n",
      "1          Length    0.096422\n",
      "0             Sex    0.031210\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       555\n",
      "           1       0.65      0.59      0.62       281\n",
      "\n",
      "    accuracy                           0.76       836\n",
      "   macro avg       0.73      0.72      0.72       836\n",
      "weighted avg       0.75      0.76      0.75       836\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       545\n",
      "           1       0.70      0.64      0.67       291\n",
      "\n",
      "    accuracy                           0.78       836\n",
      "   macro avg       0.76      0.75      0.75       836\n",
      "weighted avg       0.77      0.78      0.78       836\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.82      0.82       545\n",
      "           1       0.66      0.64      0.65       291\n",
      "\n",
      "    accuracy                           0.76       836\n",
      "   macro avg       0.73      0.73      0.73       836\n",
      "weighted avg       0.76      0.76      0.76       836\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "          Feature  Importance\n",
      "7    Shell_weight    0.209120\n",
      "5  Shucked_weight    0.156381\n",
      "4    Whole_weight    0.152401\n",
      "6  Viscera_weight    0.123272\n",
      "3          Height    0.120542\n",
      "2        Diameter    0.112655\n",
      "1          Length    0.099703\n",
      "0             Sex    0.025927\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.84      0.82       545\n",
      "           1       0.67      0.60      0.63       291\n",
      "\n",
      "    accuracy                           0.76       836\n",
      "   macro avg       0.73      0.72      0.73       836\n",
      "weighted avg       0.75      0.76      0.76       836\n",
      "\n",
      "\n",
      "Average Results:\n",
      "                           Train Score  Test Score  CV Score\n",
      "Model         Train Ratio                                   \n",
      "KNN           0.2             0.819960    0.745861  0.737325\n",
      "              0.5             0.839559    0.751077  0.761960\n",
      "              0.8             0.829093    0.759569  0.754964\n",
      "Random Forest 0.2             1.000000    0.770197  0.757685\n",
      "              0.5             1.000000    0.778682  0.780650\n",
      "              0.8             1.000000    0.773923  0.782201\n",
      "SVM           0.2             0.775250    0.772791  0.758882\n",
      "              0.5             0.790230    0.782671  0.775698\n",
      "              0.8             0.792577    0.787480  0.782601\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class AbaloneAnalysis:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def load_data(self, filepath):\n",
    "        # Create column names\n",
    "        columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', \n",
    "                  'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings']\n",
    "        \n",
    "        # Read the data\n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        \n",
    "        # Convert Sex to numerical values\n",
    "        df['Sex'] = self.le.fit_transform(df['Sex'])\n",
    "        \n",
    "        # Create binary classification (young/old based on rings)\n",
    "        df['Class'] = (df['Rings'] > 10).astype(int)\n",
    "        \n",
    "        # Split features and target\n",
    "        X = df.drop(['Rings', 'Class'], axis=1)\n",
    "        y = df['Class']\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "        \n",
    "        return X_scaled, y\n",
    "    \n",
    "    def train_and_evaluate(self, X, y, train_ratio, trial):\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=(1-train_ratio), random_state=self.random_state+trial\n",
    "        )\n",
    "        \n",
    "        models = {\n",
    "            'SVM': SVC(random_state=self.random_state),\n",
    "            'Random Forest': RandomForestClassifier(random_state=self.random_state),\n",
    "            'KNN': KNeighborsClassifier()\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        for name, model in models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Calculate scores\n",
    "            train_score = model.score(X_train, y_train)\n",
    "            test_score = model.score(X_test, y_test)\n",
    "            cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Train Ratio': train_ratio,\n",
    "                'Train Score': train_score,\n",
    "                'Test Score': test_score,\n",
    "                'CV Score': cv_score,\n",
    "                'Trial': trial\n",
    "            })\n",
    "            \n",
    "            # Print detailed results for this model\n",
    "            print(f\"\\nResults for {name} (Trial {trial}, Train Ratio {train_ratio}):\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Print feature importance for Random Forest\n",
    "            if name == 'Random Forest':\n",
    "                importance = pd.DataFrame({\n",
    "                    'Feature': X.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                print(\"\\nFeature Importance:\")\n",
    "                print(importance)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    # Initialize analysis\n",
    "    analysis = AbaloneAnalysis()\n",
    "    \n",
    "    # Load data\n",
    "    X, y = analysis.load_data('abalone.data')\n",
    "    \n",
    "    # Test different train/test ratios\n",
    "    train_ratios = [0.2, 0.5, 0.8]\n",
    "    all_results = []\n",
    "    \n",
    "    for train_ratio in train_ratios:\n",
    "        for trial in range(3):\n",
    "            results = analysis.train_and_evaluate(X, y, train_ratio, trial)\n",
    "            all_results.append(results)\n",
    "    \n",
    "    # Combine and display final results\n",
    "    final_results = pd.concat(all_results)\n",
    "    print(\"\\nAverage Results:\")\n",
    "    print(final_results.groupby(['Model', 'Train Ratio'])[['Train Score', 'Test Score', 'CV Score']].mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d0b78e-cf2c-4e01-8787-bfefee514bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96      3362\n",
      "           1       0.97      0.94      0.96      3138\n",
      "\n",
      "    accuracy                           0.96      6500\n",
      "   macro avg       0.96      0.96      0.96      6500\n",
      "weighted avg       0.96      0.96      0.96      6500\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3362\n",
      "           1       1.00      1.00      1.00      3138\n",
      "\n",
      "    accuracy                           1.00      6500\n",
      "   macro avg       1.00      1.00      1.00      6500\n",
      "weighted avg       1.00      1.00      1.00      6500\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.158609\n",
      "19         spore-print-color    0.126338\n",
      "7                  gill-size    0.119140\n",
      "8                 gill-color    0.119067\n",
      "20                population    0.060703\n",
      "18                 ring-type    0.059043\n",
      "3                    bruises    0.052688\n",
      "11  stalk-surface-above-ring    0.045232\n",
      "10                stalk-root    0.043161\n",
      "12  stalk-surface-below-ring    0.034805\n",
      "6               gill-spacing    0.032770\n",
      "21                   habitat    0.030506\n",
      "14    stalk-color-below-ring    0.021080\n",
      "13    stalk-color-above-ring    0.020750\n",
      "9                stalk-shape    0.019417\n",
      "17               ring-number    0.018084\n",
      "2                  cap-color    0.015323\n",
      "1                cap-surface    0.009038\n",
      "0                  cap-shape    0.006403\n",
      "5            gill-attachment    0.004237\n",
      "16                veil-color    0.003606\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3362\n",
      "           1       1.00      0.98      0.99      3138\n",
      "\n",
      "    accuracy                           0.99      6500\n",
      "   macro avg       0.99      0.99      0.99      6500\n",
      "weighted avg       0.99      0.99      0.99      6500\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3377\n",
      "           1       0.98      0.92      0.95      3123\n",
      "\n",
      "    accuracy                           0.96      6500\n",
      "   macro avg       0.96      0.95      0.96      6500\n",
      "weighted avg       0.96      0.96      0.96      6500\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3377\n",
      "           1       1.00      1.00      1.00      3123\n",
      "\n",
      "    accuracy                           1.00      6500\n",
      "   macro avg       1.00      1.00      1.00      6500\n",
      "weighted avg       1.00      1.00      1.00      6500\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.162119\n",
      "8                 gill-color    0.140936\n",
      "7                  gill-size    0.105254\n",
      "19         spore-print-color    0.090022\n",
      "11  stalk-surface-above-ring    0.067875\n",
      "3                    bruises    0.063255\n",
      "18                 ring-type    0.063241\n",
      "20                population    0.052192\n",
      "10                stalk-root    0.044793\n",
      "12  stalk-surface-below-ring    0.033878\n",
      "6               gill-spacing    0.032347\n",
      "21                   habitat    0.032220\n",
      "13    stalk-color-above-ring    0.020836\n",
      "2                  cap-color    0.019635\n",
      "14    stalk-color-below-ring    0.018365\n",
      "9                stalk-shape    0.016738\n",
      "17               ring-number    0.015161\n",
      "1                cap-surface    0.009005\n",
      "0                  cap-shape    0.004313\n",
      "5            gill-attachment    0.004005\n",
      "16                veil-color    0.003810\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      3377\n",
      "           1       0.99      0.97      0.98      3123\n",
      "\n",
      "    accuracy                           0.98      6500\n",
      "   macro avg       0.98      0.98      0.98      6500\n",
      "weighted avg       0.98      0.98      0.98      6500\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96      3345\n",
      "           1       0.99      0.93      0.96      3155\n",
      "\n",
      "    accuracy                           0.96      6500\n",
      "   macro avg       0.96      0.96      0.96      6500\n",
      "weighted avg       0.96      0.96      0.96      6500\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3345\n",
      "           1       1.00      0.99      1.00      3155\n",
      "\n",
      "    accuracy                           1.00      6500\n",
      "   macro avg       1.00      1.00      1.00      6500\n",
      "weighted avg       1.00      1.00      1.00      6500\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.143119\n",
      "8                 gill-color    0.117897\n",
      "19         spore-print-color    0.099439\n",
      "7                  gill-size    0.093404\n",
      "18                 ring-type    0.074419\n",
      "20                population    0.058837\n",
      "3                    bruises    0.058033\n",
      "11  stalk-surface-above-ring    0.055311\n",
      "10                stalk-root    0.054362\n",
      "6               gill-spacing    0.045086\n",
      "12  stalk-surface-below-ring    0.043013\n",
      "21                   habitat    0.036587\n",
      "13    stalk-color-above-ring    0.019817\n",
      "17               ring-number    0.019351\n",
      "9                stalk-shape    0.019033\n",
      "2                  cap-color    0.018703\n",
      "14    stalk-color-below-ring    0.018405\n",
      "1                cap-surface    0.013189\n",
      "0                  cap-shape    0.005747\n",
      "16                veil-color    0.003780\n",
      "5            gill-attachment    0.002468\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.2):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3345\n",
      "           1       1.00      0.98      0.99      3155\n",
      "\n",
      "    accuracy                           0.99      6500\n",
      "   macro avg       0.99      0.99      0.99      6500\n",
      "weighted avg       0.99      0.99      0.99      6500\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2085\n",
      "           1       0.99      0.98      0.99      1977\n",
      "\n",
      "    accuracy                           0.99      4062\n",
      "   macro avg       0.99      0.99      0.99      4062\n",
      "weighted avg       0.99      0.99      0.99      4062\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2085\n",
      "           1       1.00      1.00      1.00      1977\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.175309\n",
      "7                  gill-size    0.122096\n",
      "8                 gill-color    0.118115\n",
      "19         spore-print-color    0.112006\n",
      "20                population    0.055006\n",
      "3                    bruises    0.052781\n",
      "10                stalk-root    0.051349\n",
      "11  stalk-surface-above-ring    0.048055\n",
      "18                 ring-type    0.046700\n",
      "21                   habitat    0.032542\n",
      "6               gill-spacing    0.028525\n",
      "12  stalk-surface-below-ring    0.028474\n",
      "13    stalk-color-above-ring    0.022401\n",
      "9                stalk-shape    0.020759\n",
      "14    stalk-color-below-ring    0.020616\n",
      "17               ring-number    0.019065\n",
      "2                  cap-color    0.017952\n",
      "1                cap-surface    0.013046\n",
      "16                veil-color    0.007081\n",
      "0                  cap-shape    0.004153\n",
      "5            gill-attachment    0.003973\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2085\n",
      "           1       0.99      1.00      1.00      1977\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2109\n",
      "           1       1.00      0.97      0.99      1953\n",
      "\n",
      "    accuracy                           0.99      4062\n",
      "   macro avg       0.99      0.99      0.99      4062\n",
      "weighted avg       0.99      0.99      0.99      4062\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2109\n",
      "           1       1.00      1.00      1.00      1953\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.171565\n",
      "7                  gill-size    0.108837\n",
      "8                 gill-color    0.106221\n",
      "19         spore-print-color    0.097112\n",
      "18                 ring-type    0.071798\n",
      "3                    bruises    0.062547\n",
      "11  stalk-surface-above-ring    0.056816\n",
      "20                population    0.056619\n",
      "10                stalk-root    0.053803\n",
      "6               gill-spacing    0.036935\n",
      "21                   habitat    0.031232\n",
      "12  stalk-surface-below-ring    0.031162\n",
      "13    stalk-color-above-ring    0.020907\n",
      "17               ring-number    0.018959\n",
      "9                stalk-shape    0.018554\n",
      "2                  cap-color    0.016909\n",
      "14    stalk-color-below-ring    0.016062\n",
      "1                cap-surface    0.011220\n",
      "16                veil-color    0.004637\n",
      "0                  cap-shape    0.004063\n",
      "5            gill-attachment    0.004043\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      2109\n",
      "           1       1.00      0.99      1.00      1953\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      2062\n",
      "           1       1.00      0.97      0.98      2000\n",
      "\n",
      "    accuracy                           0.99      4062\n",
      "   macro avg       0.99      0.99      0.99      4062\n",
      "weighted avg       0.99      0.99      0.99      4062\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2062\n",
      "           1       1.00      1.00      1.00      2000\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.162181\n",
      "8                 gill-color    0.131200\n",
      "19         spore-print-color    0.103871\n",
      "7                  gill-size    0.097583\n",
      "18                 ring-type    0.066890\n",
      "20                population    0.059367\n",
      "10                stalk-root    0.054996\n",
      "3                    bruises    0.054134\n",
      "11  stalk-surface-above-ring    0.050164\n",
      "6               gill-spacing    0.035497\n",
      "21                   habitat    0.031723\n",
      "12  stalk-surface-below-ring    0.031413\n",
      "13    stalk-color-above-ring    0.025354\n",
      "14    stalk-color-below-ring    0.020257\n",
      "17               ring-number    0.018474\n",
      "9                stalk-shape    0.017345\n",
      "2                  cap-color    0.014256\n",
      "1                cap-surface    0.011310\n",
      "16                veil-color    0.005108\n",
      "0                  cap-shape    0.004876\n",
      "5            gill-attachment    0.004003\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.5):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2062\n",
      "           1       1.00      1.00      1.00      2000\n",
      "\n",
      "    accuracy                           1.00      4062\n",
      "   macro avg       1.00      1.00      1.00      4062\n",
      "weighted avg       1.00      1.00      1.00      4062\n",
      "\n",
      "\n",
      "Results for SVM (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       843\n",
      "           1       1.00      0.99      0.99       782\n",
      "\n",
      "    accuracy                           0.99      1625\n",
      "   macro avg       0.99      0.99      0.99      1625\n",
      "weighted avg       0.99      0.99      0.99      1625\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       843\n",
      "           1       1.00      1.00      1.00       782\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.170572\n",
      "7                  gill-size    0.121913\n",
      "8                 gill-color    0.115072\n",
      "19         spore-print-color    0.102634\n",
      "18                 ring-type    0.064373\n",
      "20                population    0.062443\n",
      "11  stalk-surface-above-ring    0.056446\n",
      "3                    bruises    0.052025\n",
      "10                stalk-root    0.049386\n",
      "12  stalk-surface-below-ring    0.030972\n",
      "21                   habitat    0.029253\n",
      "6               gill-spacing    0.027924\n",
      "13    stalk-color-above-ring    0.020886\n",
      "9                stalk-shape    0.020203\n",
      "17               ring-number    0.018488\n",
      "14    stalk-color-below-ring    0.017476\n",
      "2                  cap-color    0.015161\n",
      "1                cap-surface    0.011597\n",
      "0                  cap-shape    0.004967\n",
      "16                veil-color    0.004485\n",
      "5            gill-attachment    0.003725\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 0, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00       843\n",
      "           1       0.99      1.00      0.99       782\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       0.99      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Results for SVM (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       837\n",
      "           1       1.00      0.98      0.99       788\n",
      "\n",
      "    accuracy                           0.99      1625\n",
      "   macro avg       0.99      0.99      0.99      1625\n",
      "weighted avg       0.99      0.99      0.99      1625\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       837\n",
      "           1       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.165147\n",
      "7                  gill-size    0.121620\n",
      "8                 gill-color    0.112470\n",
      "19         spore-print-color    0.112155\n",
      "3                    bruises    0.059056\n",
      "18                 ring-type    0.058901\n",
      "20                population    0.058378\n",
      "10                stalk-root    0.052494\n",
      "11  stalk-surface-above-ring    0.046614\n",
      "21                   habitat    0.036297\n",
      "6               gill-spacing    0.033602\n",
      "12  stalk-surface-below-ring    0.030506\n",
      "13    stalk-color-above-ring    0.021487\n",
      "9                stalk-shape    0.018965\n",
      "14    stalk-color-below-ring    0.016912\n",
      "17               ring-number    0.016038\n",
      "2                  cap-color    0.015306\n",
      "1                cap-surface    0.010387\n",
      "16                veil-color    0.006626\n",
      "0                  cap-shape    0.003897\n",
      "5            gill-attachment    0.003143\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 1, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       837\n",
      "           1       1.00      1.00      1.00       788\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Results for SVM (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       803\n",
      "           1       1.00      0.98      0.99       822\n",
      "\n",
      "    accuracy                           0.99      1625\n",
      "   macro avg       0.99      0.99      0.99      1625\n",
      "weighted avg       0.99      0.99      0.99      1625\n",
      "\n",
      "\n",
      "Results for Random Forest (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       803\n",
      "           1       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Feature Importance:\n",
      "                     Feature  Importance\n",
      "4                       odor    0.183777\n",
      "8                 gill-color    0.118692\n",
      "7                  gill-size    0.113555\n",
      "19         spore-print-color    0.104539\n",
      "18                 ring-type    0.062088\n",
      "20                population    0.057700\n",
      "3                    bruises    0.056291\n",
      "10                stalk-root    0.053751\n",
      "11  stalk-surface-above-ring    0.047671\n",
      "21                   habitat    0.031561\n",
      "12  stalk-surface-below-ring    0.028391\n",
      "6               gill-spacing    0.026809\n",
      "13    stalk-color-above-ring    0.021375\n",
      "17               ring-number    0.019518\n",
      "9                stalk-shape    0.018317\n",
      "14    stalk-color-below-ring    0.015624\n",
      "2                  cap-color    0.015568\n",
      "1                cap-surface    0.011842\n",
      "16                veil-color    0.005593\n",
      "0                  cap-shape    0.004460\n",
      "5            gill-attachment    0.002880\n",
      "15                 veil-type    0.000000\n",
      "\n",
      "Results for KNN (Trial 2, Train Ratio 0.8):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       803\n",
      "           1       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           1.00      1625\n",
      "   macro avg       1.00      1.00      1.00      1625\n",
      "weighted avg       1.00      1.00      1.00      1625\n",
      "\n",
      "\n",
      "Average Results:\n",
      "                           Train Score  Test Score  CV Score\n",
      "Model         Train Ratio                                   \n",
      "KNN           0.2             0.995279    0.987333  0.981943\n",
      "              0.5             0.998605    0.995815  0.995733\n",
      "              0.8             0.999641    0.997744  0.998000\n",
      "Random Forest 0.2             1.000000    0.999179  1.000000\n",
      "              0.5             1.000000    1.000000  1.000000\n",
      "              0.8             1.000000    1.000000  1.000000\n",
      "SVM           0.2             0.965107    0.957333  0.958131\n",
      "              0.5             0.986870    0.985885  0.982932\n",
      "              0.8             0.990922    0.990359  0.988306\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class MushroomAnalysis:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.label_encoders = {}\n",
    "        \n",
    "    def load_data(self, filepath):\n",
    "        # Define column names\n",
    "        columns = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', \n",
    "                  'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "                  'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', \n",
    "                  'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "                  'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
    "                  'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "        \n",
    "        # Read the data\n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        \n",
    "        # Handle missing values in stalk-root\n",
    "        df['stalk-root'] = df['stalk-root'].replace('?', df['stalk-root'].mode()[0])\n",
    "        \n",
    "        # Convert target (e: edible -> 0, p: poisonous -> 1)\n",
    "        df['class'] = (df['class'] == 'p').astype(int)\n",
    "        \n",
    "        # Encode all categorical variables\n",
    "        X = df.drop('class', axis=1)\n",
    "        y = df['class']\n",
    "        \n",
    "        # Apply label encoding to all columns\n",
    "        X_encoded = X.copy()\n",
    "        for column in X.columns:\n",
    "            le = LabelEncoder()\n",
    "            X_encoded[column] = le.fit_transform(X[column])\n",
    "            self.label_encoders[column] = le\n",
    "            \n",
    "        return X_encoded, y\n",
    "    \n",
    "    def train_and_evaluate(self, X, y, train_ratio, trial):\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=(1-train_ratio), random_state=self.random_state+trial\n",
    "        )\n",
    "        \n",
    "        models = {\n",
    "            'SVM': SVC(random_state=self.random_state),\n",
    "            'Random Forest': RandomForestClassifier(random_state=self.random_state),\n",
    "            'KNN': KNeighborsClassifier()\n",
    "        }\n",
    "        \n",
    "        results = []\n",
    "        for name, model in models.items():\n",
    "            # Train model\n",
    "            model.fit(X_train, y_train)\n",
    "            \n",
    "            # Calculate scores\n",
    "            train_score = model.score(X_train, y_train)\n",
    "            test_score = model.score(X_test, y_test)\n",
    "            cv_score = np.mean(cross_val_score(model, X_train, y_train, cv=5))\n",
    "            \n",
    "            # Store results\n",
    "            results.append({\n",
    "                'Model': name,\n",
    "                'Train Ratio': train_ratio,\n",
    "                'Train Score': train_score,\n",
    "                'Test Score': test_score,\n",
    "                'CV Score': cv_score,\n",
    "                'Trial': trial\n",
    "            })\n",
    "            \n",
    "            # Print detailed results for this model\n",
    "            print(f\"\\nResults for {name} (Trial {trial}, Train Ratio {train_ratio}):\")\n",
    "            y_pred = model.predict(X_test)\n",
    "            print(classification_report(y_test, y_pred))\n",
    "            \n",
    "            # Print feature importance for Random Forest\n",
    "            if name == 'Random Forest':\n",
    "                importance = pd.DataFrame({\n",
    "                    'Feature': X.columns,\n",
    "                    'Importance': model.feature_importances_\n",
    "                }).sort_values('Importance', ascending=False)\n",
    "                print(\"\\nFeature Importance:\")\n",
    "                print(importance)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "def main():\n",
    "    # Initialize analysis\n",
    "    analysis = MushroomAnalysis()\n",
    "    \n",
    "    # Load data\n",
    "    X, y = analysis.load_data('agaricus-lepiota.data')\n",
    "    \n",
    "    # Test different train/test ratios\n",
    "    train_ratios = [0.2, 0.5, 0.8]\n",
    "    all_results = []\n",
    "    \n",
    "    for train_ratio in train_ratios:\n",
    "        for trial in range(3):\n",
    "            results = analysis.train_and_evaluate(X, y, train_ratio, trial)\n",
    "            all_results.append(results)\n",
    "    \n",
    "    # Combine and display final results\n",
    "    final_results = pd.concat(all_results)\n",
    "    print(\"\\nAverage Results:\")\n",
    "    print(final_results.groupby(['Model', 'Train Ratio'])[['Train Score', 'Test Score', 'CV Score']].mean())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9bc8d876-33c0-49f8-b82a-6d5c10e1d130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Processing Breast Cancer Dataset\n",
      "==================================================\n",
      "\n",
      "Performing grid search for SVM\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.9693\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       444\n",
      "           1       0.95      0.97      0.96       239\n",
      "\n",
      "    accuracy                           0.97       683\n",
      "   macro avg       0.97      0.97      0.97       683\n",
      "weighted avg       0.97      0.97      0.97       683\n",
      "\n",
      "\n",
      "Performing grid search for RF\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for RF:\n",
      "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.9664\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99       444\n",
      "           1       0.98      1.00      0.99       239\n",
      "\n",
      "    accuracy                           0.99       683\n",
      "   macro avg       0.99      0.99      0.99       683\n",
      "weighted avg       0.99      0.99      0.99       683\n",
      "\n",
      "\n",
      "Performing grid search for KNN\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "{'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Best cross-validation score: 0.9664\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       444\n",
      "           1       0.96      0.97      0.96       239\n",
      "\n",
      "    accuracy                           0.97       683\n",
      "   macro avg       0.97      0.97      0.97       683\n",
      "weighted avg       0.97      0.97      0.97       683\n",
      "\n",
      "\n",
      "Summary of results:\n",
      "         Dataset Model                                    Best Parameters  \\\n",
      "0  Breast Cancer   SVM   {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}   \n",
      "1  Breast Cancer    RF  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
      "2  Breast Cancer   KNN           {'n_neighbors': 5, 'weights': 'uniform'}   \n",
      "\n",
      "   Best Score  \n",
      "0    0.969289  \n",
      "1    0.966380  \n",
      "2    0.966380  \n",
      "\n",
      "==================================================\n",
      "Processing Abalone Dataset\n",
      "==================================================\n",
      "\n",
      "Performing grid search for SVM\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best cross-validation score: 0.7807\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      2730\n",
      "           1       0.75      0.65      0.70      1447\n",
      "\n",
      "    accuracy                           0.80      4177\n",
      "   macro avg       0.79      0.77      0.78      4177\n",
      "weighted avg       0.80      0.80      0.80      4177\n",
      "\n",
      "\n",
      "Performing grid search for RF\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for RF:\n",
      "{'max_depth': 10, 'min_samples_split': 5, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.7785\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      2730\n",
      "           1       0.91      0.79      0.85      1447\n",
      "\n",
      "    accuracy                           0.90      4177\n",
      "   macro avg       0.90      0.88      0.89      4177\n",
      "weighted avg       0.90      0.90      0.90      4177\n",
      "\n",
      "\n",
      "Performing grid search for KNN\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "{'n_neighbors': 9, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.7541\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2730\n",
      "           1       1.00      1.00      1.00      1447\n",
      "\n",
      "    accuracy                           1.00      4177\n",
      "   macro avg       1.00      1.00      1.00      4177\n",
      "weighted avg       1.00      1.00      1.00      4177\n",
      "\n",
      "\n",
      "Summary of results:\n",
      "   Dataset Model                                    Best Parameters  \\\n",
      "0  Abalone   SVM       {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}   \n",
      "1  Abalone    RF  {'max_depth': 10, 'min_samples_split': 5, 'n_e...   \n",
      "2  Abalone   KNN          {'n_neighbors': 9, 'weights': 'distance'}   \n",
      "\n",
      "   Best Score  \n",
      "0    0.780704  \n",
      "1    0.778548  \n",
      "2    0.754131  \n",
      "\n",
      "==================================================\n",
      "Processing Mushroom Dataset\n",
      "==================================================\n",
      "\n",
      "Performing grid search for SVM\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for SVM:\n",
      "{'C': 10, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Best cross-validation score: 0.8972\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      4208\n",
      "           1       0.98      1.00      0.99      3916\n",
      "\n",
      "    accuracy                           0.99      8124\n",
      "   macro avg       0.99      0.99      0.99      8124\n",
      "weighted avg       0.99      0.99      0.99      8124\n",
      "\n",
      "\n",
      "Performing grid search for RF\n",
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
      "\n",
      "Best parameters for RF:\n",
      "{'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Best cross-validation score: 0.8971\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4208\n",
      "           1       1.00      1.00      1.00      3916\n",
      "\n",
      "    accuracy                           1.00      8124\n",
      "   macro avg       1.00      1.00      1.00      8124\n",
      "weighted avg       1.00      1.00      1.00      8124\n",
      "\n",
      "\n",
      "Performing grid search for KNN\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "\n",
      "Best parameters for KNN:\n",
      "{'n_neighbors': 3, 'weights': 'distance'}\n",
      "Best cross-validation score: 0.8933\n",
      "\n",
      "Training Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4208\n",
      "           1       1.00      1.00      1.00      3916\n",
      "\n",
      "    accuracy                           1.00      8124\n",
      "   macro avg       1.00      1.00      1.00      8124\n",
      "weighted avg       1.00      1.00      1.00      8124\n",
      "\n",
      "\n",
      "Summary of results:\n",
      "    Dataset Model                                    Best Parameters  \\\n",
      "0  Mushroom   SVM    {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}   \n",
      "1  Mushroom    RF  {'max_depth': 20, 'min_samples_split': 2, 'n_e...   \n",
      "2  Mushroom   KNN          {'n_neighbors': 3, 'weights': 'distance'}   \n",
      "\n",
      "   Best Score  \n",
      "0    0.897208  \n",
      "1    0.897064  \n",
      "2    0.893251  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class ModelAnalysis:\n",
    "    def __init__(self, random_state=42):\n",
    "        self.random_state = random_state\n",
    "        self.scaler = StandardScaler()\n",
    "        self.le = LabelEncoder()\n",
    "        \n",
    "    def perform_grid_search(self, X, y, model_type):\n",
    "        \"\"\"Perform grid search for hyperparameter tuning\"\"\"\n",
    "        if model_type == 'SVM':\n",
    "            param_grid = {\n",
    "                'C': [0.1, 1, 10],\n",
    "                'kernel': ['rbf', 'linear'],\n",
    "                'gamma': ['scale', 'auto']\n",
    "            }\n",
    "            model = SVC(random_state=self.random_state)\n",
    "            \n",
    "        elif model_type == 'RF':\n",
    "            param_grid = {\n",
    "                'n_estimators': [100, 200],\n",
    "                'max_depth': [10, 20, None],\n",
    "                'min_samples_split': [2, 5]\n",
    "            }\n",
    "            model = RandomForestClassifier(random_state=self.random_state)\n",
    "            \n",
    "        else:  # KNN\n",
    "            param_grid = {\n",
    "                'n_neighbors': [3, 5, 7, 9],\n",
    "                'weights': ['uniform', 'distance']\n",
    "            }\n",
    "            model = KNeighborsClassifier()\n",
    "        \n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X, y)\n",
    "        \n",
    "        print(f\"\\nBest parameters for {model_type}:\")\n",
    "        print(grid_search.best_params_)\n",
    "        print(f\"Best cross-validation score: {grid_search.best_score_:.4f}\")\n",
    "        \n",
    "        # Test the best model\n",
    "        y_pred = grid_search.predict(X)\n",
    "        print(\"\\nTraining Performance:\")\n",
    "        print(classification_report(y, y_pred))\n",
    "        \n",
    "        return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_\n",
    "\n",
    "    def process_breast_cancer_data(self, filepath):\n",
    "        columns = ['id', 'clump_thickness', 'cell_size_uniformity', \n",
    "                  'cell_shape_uniformity', 'marginal_adhesion', \n",
    "                  'epithelial_cell_size', 'bare_nuclei', 'bland_chromatin',\n",
    "                  'normal_nucleoli', 'mitoses', 'class']\n",
    "        \n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        df = df.replace('?', np.nan).dropna()\n",
    "        \n",
    "        for col in df.columns:\n",
    "            if col != 'id':\n",
    "                df[col] = pd.to_numeric(df[col])\n",
    "        \n",
    "        df['class'] = (df['class'] == 4).astype(int)\n",
    "        X = df.drop(['id', 'class'], axis=1)\n",
    "        y = df['class']\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        return X_scaled, y\n",
    "\n",
    "    def process_abalone_data(self, filepath):\n",
    "        columns = ['Sex', 'Length', 'Diameter', 'Height', 'Whole_weight', \n",
    "                  'Shucked_weight', 'Viscera_weight', 'Shell_weight', 'Rings']\n",
    "        \n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        df['Sex'] = self.le.fit_transform(df['Sex'])\n",
    "        df['Class'] = (df['Rings'] > 10).astype(int)\n",
    "        \n",
    "        X = df.drop(['Rings', 'Class'], axis=1)\n",
    "        y = df['Class']\n",
    "        \n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        return X_scaled, y\n",
    "\n",
    "    def process_mushroom_data(self, filepath):\n",
    "        columns = ['class', 'cap-shape', 'cap-surface', 'cap-color', 'bruises', \n",
    "                  'odor', 'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n",
    "                  'stalk-shape', 'stalk-root', 'stalk-surface-above-ring', \n",
    "                  'stalk-surface-below-ring', 'stalk-color-above-ring',\n",
    "                  'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n",
    "                  'ring-type', 'spore-print-color', 'population', 'habitat']\n",
    "        \n",
    "        df = pd.read_csv(filepath, header=None, names=columns)\n",
    "        df['stalk-root'] = df['stalk-root'].replace('?', df['stalk-root'].mode()[0])\n",
    "        df['class'] = (df['class'] == 'p').astype(int)\n",
    "        \n",
    "        # Encode all categorical variables\n",
    "        X = df.drop('class', axis=1)\n",
    "        y = df['class']\n",
    "        \n",
    "        label_encoders = {}\n",
    "        X_encoded = pd.DataFrame()\n",
    "        \n",
    "        for column in X.columns:\n",
    "            label_encoders[column] = LabelEncoder()\n",
    "            X_encoded[column] = label_encoders[column].fit_transform(X[column])\n",
    "            \n",
    "        return X_encoded, y\n",
    "\n",
    "def main():\n",
    "    analysis = ModelAnalysis()\n",
    "    \n",
    "    # Process each dataset\n",
    "    datasets = {\n",
    "        'Breast Cancer': ('breast-cancer-wisconsin.data', analysis.process_breast_cancer_data),\n",
    "        'Abalone': ('abalone.data', analysis.process_abalone_data),\n",
    "        'Mushroom': ('agaricus-lepiota.data', analysis.process_mushroom_data)\n",
    "    }\n",
    "    \n",
    "    for dataset_name, (filepath, process_func) in datasets.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {dataset_name} Dataset\")\n",
    "        print('='*50)\n",
    "        \n",
    "        # Load and process data\n",
    "        X, y = process_func(filepath)\n",
    "        \n",
    "        # Perform grid search for each model\n",
    "        models = ['SVM', 'RF', 'KNN']\n",
    "        results = []\n",
    "        \n",
    "        for model_type in models:\n",
    "            print(f\"\\nPerforming grid search for {model_type}\")\n",
    "            best_model, best_params, best_score = analysis.perform_grid_search(X, y, model_type)\n",
    "            \n",
    "            results.append({\n",
    "                'Dataset': dataset_name,\n",
    "                'Model': model_type,\n",
    "                'Best Parameters': best_params,\n",
    "                'Best Score': best_score\n",
    "            })\n",
    "        \n",
    "        # Display summary of results\n",
    "        print(\"\\nSummary of results:\")\n",
    "        results_df = pd.DataFrame(results)\n",
    "        print(results_df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74d2f72-cdbb-45a1-9597-2263be98b1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
